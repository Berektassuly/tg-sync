# tg-sync – copy to .env and fill in your values
# Get API ID and API hash from https://my.telegram.org/apps

# Required for Telegram API
TG_SYNC_API_ID=your_api_id
TG_SYNC_API_HASH=your_api_hash

# Optional: paths (defaults shown)
# TG_SYNC_DATA_DIR=./data
# TG_SYNC_SESSION_PATH=./session.db   (default: CWD; kept separate from data/)

# Optional: extra config file (e.g. config.toml)
# TG_SYNC_CONFIG=config.toml

# Optional: delay in ms between message-history API requests (rate limiting, avoid FloodWait)
# EXPORT_DELAY_MS=500

# Optional: delay in ms between sync batch requests (avoids FLOOD_WAIT). Default: 500
# SYNC_DELAY_MS=1000

# ─────────────────────────────────────────────────────────────────────────────
# AI Analysis Configuration (Mode 3)
# ─────────────────────────────────────────────────────────────────────────────

# Optional: OpenAI API key (or compatible API like Azure OpenAI, Ollama)
# If not set, the mock adapter is used (no real LLM calls)
# TG_SYNC_AI_API_KEY=sk-...

# Optional: API endpoint URL. Defaults to OpenAI chat completions.
# For Ollama: http://localhost:11434/v1/chat/completions
# TG_SYNC_AI_API_URL=https://api.openai.com/v1/chat/completions

# Optional: Model name. Defaults to gpt-4o-mini.
# For Ollama: llama3.2, mistral, etc.
# TG_SYNC_AI_MODEL=gpt-4o-mini

# MTProto DCs and keys are built into the grammers client;
# no need to set them here unless you add custom DC support.
